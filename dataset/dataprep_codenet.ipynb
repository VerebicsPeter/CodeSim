{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/peter/Downloads/Project_CodeNet/data\"\n",
    "META_PATH = \"/home/peter/Downloads/Project_CodeNet/metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rapidfuzz\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader Functions\n",
    "\n",
    "\n",
    "def init_df(path: str) -> pd.DataFrame:\n",
    "    if not os.path.isfile(path):\n",
    "        return\n",
    "    df: pd.DataFrame = pd.read_csv(os.path.join(path))\n",
    "    # Filter:\n",
    "    df = df[['submission_id','status','language','user_id','date','accuracy']]\n",
    "    df = df.loc['Python'  == df['language']]\n",
    "    df = df.loc[1577836800 < df['date']] # > 2020 jan 1\n",
    "    df = df[['submission_id','status']]\n",
    "    return df\n",
    "\n",
    "\n",
    "def pair_series(sr_x, sr_y, n_pairs, col_x: str, col_y: str) -> pd.DataFrame:\n",
    "    assert len(sr_x) == len(sr_y)\n",
    "    n_rows = len(sr_x)\n",
    "    if n_rows < 2 * n_pairs:\n",
    "        raise ValueError(\"Too many pairs.\")\n",
    "    inds = np.random.choice(n_rows, size=2 * n_pairs, replace=False)\n",
    "    inds_x, inds_y = inds[:n_pairs], inds[n_pairs:]\n",
    "    pairs = [\n",
    "        (sr_x.iloc[i], sr_y.iloc[j]) for i,j in zip(inds_x,inds_y)\n",
    "    ]\n",
    "    return pd.DataFrame(pairs, columns=[f'{col_x}_x', f'{col_y}_y'])\n",
    "\n",
    "\n",
    "def read_file(pid, sid):\n",
    "    file_path = os.path.abspath(os.path.join(DATA_PATH, pid, 'Python'))\n",
    "    fp =        os.path.abspath(os.path.join(file_path, f'{sid}.py'))\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def process_pid(pid: str, ac_data_map: dict, re_data_map: dict):\n",
    "    MIN_PAIRS = 1\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join(DATA_PATH, pid, 'Python'))\n",
    "    if not os.path.isdir(file_path):\n",
    "        return\n",
    "    files = os.listdir(file_path)\n",
    "    if len(files) <= 5:\n",
    "        return\n",
    "    meta_path = os.path.join(META_PATH, f'{pid}.csv')\n",
    "    print(meta_path)\n",
    "    \n",
    "    df = init_df(meta_path)\n",
    "    df_acccepted = df.loc['Accepted'== df['status']]\n",
    "    df_rejected  = df.loc['Accepted'!= df['status']]\n",
    "    \n",
    "    accepted_count, rejected_count = df_acccepted.shape[0], df_rejected.shape[0]\n",
    "    print('accepted:', accepted_count)\n",
    "    print('rejected:', rejected_count)\n",
    "    \n",
    "    n_rows = min(accepted_count, rejected_count)\n",
    "    if n_rows < 2 * MIN_PAIRS:\n",
    "        return\n",
    "    \n",
    "    df_acccepted = df_acccepted['submission_id']\n",
    "    df_acccepted = df_acccepted.iloc[:n_rows]\n",
    "    df_pp = pair_series(df_acccepted, df_acccepted, n_rows//2, 'sid', 'sid')\n",
    "    \n",
    "    df_rejected = df_rejected['submission_id']\n",
    "    df_rejected = df_rejected.iloc[:n_rows]\n",
    "    df_np = pair_series(df_acccepted, df_rejected, n_rows//2, 'sid', 'sid')\n",
    "    \n",
    "    def create_pair(pid, sid_x, sid_y, label: int):\n",
    "        return {\n",
    "            \"pid\"  : pid,\n",
    "            \"sid_x\": sid_x,\n",
    "            \"sid_y\": sid_y,\n",
    "            \"src_x\": read_file(pid, sid_x),\n",
    "            \"src_y\": read_file(pid, sid_y),\n",
    "            \"label\": label\n",
    "        }\n",
    "    \n",
    "    if n_positive_pairs := df_pp.shape[0]:\n",
    "        ssize = n_positive_pairs//2\n",
    "        ac_rows = [tuple(row) for _, row in df_pp.sample(ssize).iterrows()]\n",
    "        ac_data_map[pid] = [\n",
    "            create_pair(pid, sid_x, sid_y, label=1)\n",
    "            for sid_x, sid_y in ac_rows\n",
    "        ]\n",
    "\n",
    "    if n_negative_pairs := df_np.shape[0]:\n",
    "        ssize = n_negative_pairs//2\n",
    "        re_rows = [tuple(row) for _, row in df_np.sample(ssize).iterrows()]\n",
    "        re_data_map[pid] = [\n",
    "            create_pair(pid, sid_x, sid_y, label=0)\n",
    "            for sid_x, sid_y in re_rows\n",
    "        ]\n",
    "\n",
    "\n",
    "def test():\n",
    "    _pids = os.listdir(DATA_PATH)\n",
    "    _pids = random.sample(_pids, k=1)\n",
    "    process_pid('p03200', {}, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "SAMPLE_SIZE = 2000\n",
    "\n",
    "_pids = os.listdir(DATA_PATH)\n",
    "_pids = random.sample(_pids, k=min(SAMPLE_SIZE, 4053))\n",
    "\n",
    "ac_data = {}\n",
    "re_data = {}\n",
    "\n",
    "print('Starting...')\n",
    "print(f'Processing {len(_pids)} problems.')\n",
    "\n",
    "for _pid in _pids:\n",
    "    process_pid(_pid, ac_data, re_data)\n",
    "\n",
    "print('Data gathered...')\n",
    "\n",
    "pp_output = []\n",
    "np_output = []\n",
    "for pid in ac_data:\n",
    "    for data in ac_data[pid]:\n",
    "        pp_output.append((pid,\n",
    "            data['sid_x'], data['sid_y'],\n",
    "            data['src_x'], data['src_y'],\n",
    "            data['label'],))\n",
    "for pid in re_data:\n",
    "    for data in re_data[pid]:\n",
    "        np_output.append((pid,\n",
    "            data['sid_x'], data['sid_y'],\n",
    "            data['src_x'], data['src_y'],\n",
    "            data['label'],))\n",
    "\n",
    "print(f'POSITIVE pairs created... LENGTH: {len(pp_output)}')\n",
    "print(f'NEGATIVE pairs created... LENGTH: {len(np_output)}')\n",
    "\n",
    "pp_output = list(sorted(set(pp_output), key = lambda x:(x[0],x[1])))\n",
    "np_output = list(sorted(set(np_output), key = lambda x:(x[0],x[1])))\n",
    "\n",
    "pp_len, np_len = len(pp_output), len(np_output)\n",
    "\n",
    "print(f'POSITIVE pair content filtered... LENGTH: {pp_len}')\n",
    "print(f'NEGATIVE pair content filtered... LENGTH: {np_len}')\n",
    "\n",
    "print('DONE')\n",
    "\n",
    "columns = ['pid','sid_x', 'sid_y', 'src_x', 'src_y', 'label']\n",
    "# positive pairs\n",
    "pp_output = pd.DataFrame(pp_output, columns=columns)\n",
    "# negative pairs\n",
    "np_output = pd.DataFrame(np_output, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating rapid fuzz\n",
    "\n",
    "def run_rf(a,b): return rapidfuzz.fuzz.ratio(a,b)\n",
    "\n",
    "pp_output['rf_ratio'] = pp_output.apply(lambda row: run_rf(row['src_x'], row['src_y']), axis=1)\n",
    "np_output['rf_ratio'] = np_output.apply(lambda row: run_rf(row['src_x'], row['src_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapid fuzz counts\n",
    "print('pp gt 80%:', (pp_output['rf_ratio']>80).sum())\n",
    "print('np gt 80%:', (np_output['rf_ratio']>80).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapid fuzz histograms\n",
    "import matplotlib.pyplot as plt\n",
    "res = 32\n",
    "# histogram\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "ax[0].hist(np_output['rf_ratio'], bins=res)\n",
    "ax[0].set_xlabel('rf ratio on negative pairs')\n",
    "ax[1].hist(pp_output['rf_ratio'], bins=res)\n",
    "ax[1].set_xlabel('rf ratio on positive pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and sampling\n",
    "pp_output = pp_output.sample(5000)\n",
    "#np_output = np_output[np_output['rf_ratio'] > 80]\n",
    "np_output = np_output.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "pp_output = pp_output[columns]\n",
    "np_output = np_output[columns]\n",
    "output = pd.concat([pp_output, np_output], ignore_index=True)\n",
    "output.to_csv('training_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_1.csv')\n",
    "len(set(df['pid']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
