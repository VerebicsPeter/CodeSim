{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9rC5t03TgEv"
      },
      "source": [
        "# Code Similarity with Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHWMVk9vTgE3"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cNViP9VnTgE4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pprint as pp\n",
        "import random\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "# Hugging Face Transformers (fro CodeBERT etc.)\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "# Libraries for logging\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtfdWw8jTgE7",
        "outputId": "9cd98f8b-340d-4af3-ba4a-8ec11577f30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf3-sQApVVAn"
      },
      "source": [
        "## Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k4ywg5hPVPKc"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "set_seed(seed_value=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsY6hOil070N"
      },
      "source": [
        "## Dataset Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YS9pegh1dDj4"
      },
      "outputs": [],
      "source": [
        "#paired_dataset_url = \"https://drive.google.com/uc?export=download&id=1fT4aEyIRzlqDcMFyyKkxgYN3-TGB5qqu\"  # 40k dataset\n",
        "paired_dataset_url = \"https://drive.google.com/uc?export=download&id=1pUErbyZw1fBC5gIe6KT7BWga7h6Bfr4l\"  # 100k dataset (TODO: train on this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uws_FYLpwDr0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a32WbZF4CHYZ"
      },
      "outputs": [],
      "source": [
        "COLUMNS = [\n",
        "    'pid',    # CodeNet problem ID\n",
        "    'sid_1',  # CodeNet solution ID of 'src_1'\n",
        "    'sid_2',  # CodeNet solution ID of 'src_2'\n",
        "    'src_1',  # CodeNet solution code of 'sid_1'\n",
        "    'src_2',  # CodeNet solution code of 'sid_2'\n",
        "    'label',  # Label indicating if 'src_1' and 'src_2' both solve 'pid'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Bis_8g7kCHYb"
      },
      "outputs": [],
      "source": [
        "def downsample_df(df: pd.DataFrame, samples_per_class, seed=42):\n",
        "    pos_df = df[df['label'] == 1]\n",
        "    neg_df = df[df['label'] == 0]\n",
        "    pos_sampled = neg_df.sample(n=min(samples_per_class, len(pos_df)), random_state=seed)\n",
        "    neg_sampled = pos_df.sample(n=min(samples_per_class, len(neg_df)), random_state=seed)\n",
        "    # Combine the downsampled dataframes\n",
        "    downsampled_df = pd.concat([pos_sampled, neg_sampled]).reset_index(drop=True)\n",
        "    return downsampled_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(paired_dataset_url, header=0, names=COLUMNS)\n",
        "df = df.drop(columns=['pid', 'sid_1', 'sid_2'])\n",
        "print(df['label'].value_counts())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5ellJOOTkWZ9",
        "outputId": "ceb0450c-43e7-4ef8-e14f-7bc7ef793547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    50000\n",
            "0    50000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               src_1  \\\n",
              "0  import math\\n\\na, b, h, m = map(int, input().s...   \n",
              "1                         n = input()\\nprint(n[0:3])   \n",
              "2  n=int(input())\\na=sorted(list(map(int,input()....   \n",
              "3  # -*- coding: utf-8 -*-\\n\\ns = sorted(list(map...   \n",
              "4  N, K = map(int,input().split())\\nR,S,P = map(i...   \n",
              "\n",
              "                                               src_2  label  \n",
              "0  import math\\nA,B,H,M=map(int,input().split())\\...      1  \n",
              "1                        \\ns = input()\\nprint(s[:3])      1  \n",
              "2  n = int(input())\\na = list(map(int, input().sp...      1  \n",
              "3  a,b,c = sorted(map(int,input().split()))\\n\\npr...      1  \n",
              "4  n, k = map(int, input().split())\\ns, p, r = ma...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73176e44-58af-414e-9532-269c4f56e2ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_1</th>\n",
              "      <th>src_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>import math\\n\\na, b, h, m = map(int, input().s...</td>\n",
              "      <td>import math\\nA,B,H,M=map(int,input().split())\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n = input()\\nprint(n[0:3])</td>\n",
              "      <td>\\ns = input()\\nprint(s[:3])</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n=int(input())\\na=sorted(list(map(int,input()....</td>\n",
              "      <td>n = int(input())\\na = list(map(int, input().sp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># -*- coding: utf-8 -*-\\n\\ns = sorted(list(map...</td>\n",
              "      <td>a,b,c = sorted(map(int,input().split()))\\n\\npr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N, K = map(int,input().split())\\nR,S,P = map(i...</td>\n",
              "      <td>n, k = map(int, input().split())\\ns, p, r = ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73176e44-58af-414e-9532-269c4f56e2ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73176e44-58af-414e-9532-269c4f56e2ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73176e44-58af-414e-9532-269c4f56e2ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-636d9525-c553-45fb-bcf6-2bc4402b47b0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-636d9525-c553-45fb-bcf6-2bc4402b47b0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-636d9525-c553-45fb-bcf6-2bc4402b47b0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"src_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90583,\n        \"samples\": [\n          \"s=input()+\\\"O\\\"\\ntmp=\\\"\\\"\\nans=[]\\nfor i in s:\\n  if i in [\\\"A\\\",\\\"T\\\",\\\"G\\\",\\\"C\\\"]:\\n    tmp=tmp+i\\n  else:\\n    ans.append(tmp)\\n    tmp=\\\"\\\"\\nres=0\\nfor i in ans:\\n  if len(i)>res:\\n    res=len(i)\\nprint(res)\\n\",\n          \"import math\\n#import numpy as np\\nimport queue\\nfrom collections import deque,defaultdict\\nimport heapq\\nfrom sys import stdin,setrecursionlimit\\n#from scipy.sparse.csgraph import dijkstra\\n#from scipy.sparse import csr_matrix\\nipt = stdin.readline\\nsetrecursionlimit(10**7)\\n\\ndef main():\\n    n = int(ipt())\\n    a = [int(i) for i in ipt().split()]\\n    suma = sum(a)\\n    ans = 0\\n    can = 1\\n    for i,ai in enumerate(a):\\n        if ai > can:\\n            print(-1)\\n            exit()\\n        suma -= ai\\n        ans += can\\n        if (can-ai)*2 >= suma:\\n            can = suma\\n        else:\\n            can = (can-ai)*2\\n\\n    print(ans)\\n\\n\\n\\n\\n    return\\n\\nif __name__ == '__main__':\\n    main()\\n\",\n          \"n = int(input())\\na = list(map(int, input().split()))\\nx = 0\\nfor i in a:\\n    x ^= i\\nfor i in range(n):\\n    a[i] ^= x\\nprint(*a)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97182,\n        \"samples\": [\n          \"import numpy as np\\nn,k = map(int,input().split())\\nm = 10**9 + 7\\ngcds = np.zeros(k+1, int)\\n\\nfor i in range(k,0,-1):\\n  tmp = k // i\\n  gcds[i] = pow(tmp,n, m)\\n  for j in range(tmp,1,-1):\\n    gcds[i] -= gcds[j*i]\\nans = 0\\nfor i in range(k,0,-1):\\n  ans = (ans + gcds[i]*i)%m\\nprint(ans)\",\n          \"from collections import Counter\\nn = int(input())\\ns = [0]*n\\nfor i in range(n):\\n  s[i] = input()\\ndum = Counter(s)\\ns_most = dum.most_common()\\ns_len = len(s_most)\\nans = 0\\nfor i in range(s_len):\\n  if s_most[i][1]%2 != 0:\\n    ans += 1\\nprint(ans)\",\n          \"# coding: utf-8\\nimport sys\\nimport itertools\\n\\nsr = lambda: sys.stdin.readline().rstrip()\\nir = lambda: int(sr())\\nlr = lambda: list(map(int, sr().split()))\\n\\nN = ir()\\nanswer = 0\\ndigit = len(str(N))\\n# 3, 5, 7\\u3060\\u3051\\u3067\\u3067\\u304d\\u305f\\u6570\\u3092\\u5217\\u6319\\nfor d in range(3, digit+1):\\n    for x in itertools.product(['3', '5', '7'], repeat=d):\\n        if len(set(x)) != 3:\\n            continue\\n        y = int(''.join(x))\\n        if y <= N:\\n            answer += 1\\n\\nprint(answer)\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "boNhtBMiTgFB"
      },
      "outputs": [],
      "source": [
        "# Code datasets (for labeled and unlabeled code snippets)\n",
        "\n",
        "class CodePairDataset(Dataset):\n",
        "    def __init__(self, codes_a, codes_b, labels, tokenizer):\n",
        "        super().__init__()\n",
        "        assert len(codes_a) == len(codes_b) == len(labels), \"Length MUST match!\"\n",
        "        self.codes_a = codes_a\n",
        "        self.codes_b = codes_b\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        code_a = self.codes_a[idx]\n",
        "        code_b = self.codes_b[idx]\n",
        "        label = self.labels[idx]\n",
        "        # Encode the sequences for sequence pair classification\n",
        "        # ([CLS], code_a tokens , [SEP], code_b tokens, [SEP])\n",
        "        encoding = self.tokenizer(\n",
        "            code_a, code_b,\n",
        "            padding='max_length',  # Pad to max_length\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "            truncation=True,       # Truncate to max_length\n",
        "            return_tensors='pt'    # Return torch.Tensor objects\n",
        "        )\n",
        "        # Remove batch dimension\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "        return encoding, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pandas_df(cls, df: pd.DataFrame, tokenizer, num_pairs=5000):\n",
        "        # Filter sequences that don't fit the model's max length\n",
        "        def filter_too_long_sequences(row):\n",
        "            source = row['src_1'] + row['src_2']\n",
        "            tokens = tokenizer.encode(source, truncation=False)\n",
        "            return len(tokens) <= tokenizer.model_max_length\n",
        "\n",
        "        print('filtering dataset, this might take a while ...')\n",
        "        df = df[df.apply(filter_too_long_sequences, axis=1)]\n",
        "        print('filtered dataset:', df.shape)\n",
        "        df = downsample_df(df, samples_per_class=(num_pairs // 2))\n",
        "        print('downsampled dataset:', df.shape)\n",
        "\n",
        "        codes_a = df['src_1'].to_list()\n",
        "        codes_b = df['src_2'].to_list()\n",
        "        labels = df['label'].to_list()\n",
        "\n",
        "        return cls(codes_a, codes_b, labels, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0yWCEhrTgE-"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I66sH2KATgE_"
      },
      "outputs": [],
      "source": [
        "# Model for finetuning\n",
        "\n",
        "BEST_MODEL_PATH = \"best_model.pt\"\n",
        "\n",
        "class CodeSimilarityClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "        bert,  # BERT based model instance\n",
        "        freeze_bert=False,\n",
        "        dropout_rate=0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "        self.cls = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, bert_input) -> torch.Tensor:\n",
        "        with torch.device(device):\n",
        "            bert_output = self.bert(**bert_input)\n",
        "            pooler_output = bert_output.pooler_output\n",
        "            pooler_output = self.drop(pooler_output)\n",
        "            logits = self.cls(pooler_output)\n",
        "            return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCRPRlQav58Y"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enULAgCJTgFC"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(\n",
        "    model, device,\n",
        "    loss_func,\n",
        "    scaler,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    dataloader,\n",
        "    iters_to_accumulate,\n",
        "    # for logging\n",
        "    print_every=10\n",
        "):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    num_iter = len(dataloader)\n",
        "    for iter, (encoding, labels) in enumerate(tqdm(dataloader)):\n",
        "        # Converting to cuda tensors\n",
        "        for k, v in encoding.items(): encoding[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Obtaining the logits from the model\n",
        "        # Enables autocasting for the forward pass (model + loss)\n",
        "        with autocast('cuda'):\n",
        "            # Obtaining the logits from the model\n",
        "            logits = model(encoding)\n",
        "            # Computing loss\n",
        "            loss = loss_func(logits.squeeze(-1), labels.float())\n",
        "            # Normalize the loss because it is averaged\n",
        "            loss = loss / iters_to_accumulate\n",
        "\n",
        "        # Backpropagating the gradients\n",
        "        # Scales loss. (calls backward() on scaled loss to create scaled gradients)\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (iter + 1) % iters_to_accumulate == 0:\n",
        "            # Optimization step\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
        "            # otherwise, opti.step() is skipped.\n",
        "            scaler.step(optimizer)\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "            # Adjust the learning rate based on the number of iterations.\n",
        "            scheduler.step()\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print training loss information\n",
        "        if (iter + 1) % print_every == 0:\n",
        "            print(\n",
        "                f\"Iteration {iter+1}/{num_iter} complete. \" +\n",
        "                f\"Loss: {running_loss / print_every}\"\n",
        "            )\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "def evaluate_loss(\n",
        "    model, device,\n",
        "    loss_func,\n",
        "    dataloader\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    loss, count = 0,0\n",
        "    with torch.no_grad():\n",
        "        for _, (encoding, labels) in enumerate(tqdm(dataloader)):\n",
        "            # Converting to cuda tensors\n",
        "            for k, v in encoding.items(): encoding[k] = v.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(encoding)\n",
        "            loss += loss_func(logits.squeeze(-1), labels.float()).item()\n",
        "            count += 1\n",
        "\n",
        "    mean_loss = loss / count\n",
        "    return mean_loss\n",
        "\n",
        "\n",
        "def train_bert(\n",
        "    model,\n",
        "    loss_func,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_loader, valid_loader,\n",
        "    epochs,\n",
        "    iters_to_accumulate\n",
        "):\n",
        "    best_loss = np.Inf\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Compute training loss\n",
        "        train_loss = train_one_epoch(\n",
        "            model, device, loss_func,\n",
        "            scaler,  # grad scaler\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            train_loader,\n",
        "            iters_to_accumulate,\n",
        "            # print the training loss 5 times per epoch\n",
        "            print_every=len(train_loader) // 5\n",
        "        )\n",
        "        # Compute validation loss\n",
        "        valid_loss = evaluate_loss(\n",
        "            model, device, loss_func,\n",
        "            valid_loader\n",
        "        )\n",
        "        print(f\"Epoch {epoch+1} complete! Validation Loss: {valid_loss}\")\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            print(f\"Best validation loss improved from {best_loss} to {valid_loss}\")\n",
        "            best_loss = valid_loss\n",
        "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfGO1Ktjeq7T"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "\n",
        "bert_name = \"huggingface/CodeBERTa-small-v1\"\n",
        "\n",
        "\"\"\"\n",
        "other checkpoints:\n",
        "- \"microsoft/codebert-base\"\n",
        "- \"neulab/codebert-python\"\n",
        "\"\"\"\n",
        "\n",
        "epochs = 4\n",
        "lr = 1e-5  # learning rate\n",
        "wd = 1e-5  # weight decay\n",
        "bs = 20    # batch size\n",
        "# The gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate.\n",
        "# If set to \"1\", you get the usual batch size\n",
        "iters_to_accumulate = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w5HC1kY9aMdx"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
        "\n",
        "dataset = CodePairDataset.from_pandas_df(df, bert_tokenizer, num_pairs=50_000)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "SHUFFLE = True\n",
        "train_loader = DataLoader(train_data, batch_size=bs, shuffle=SHUFFLE)\n",
        "valid_loader = DataLoader(valid_data, batch_size=bs, shuffle=SHUFFLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RmsA8R0JTgFD"
      },
      "outputs": [],
      "source": [
        "# Model instance\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(bert_name).to(device)\n",
        "\n",
        "model = CodeSimilarityClassifier(bert_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FEJc8HelobGZ"
      },
      "outputs": [],
      "source": [
        "# Optimizer and Scheduler\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "# The number of steps for the warmup phase.\n",
        "num_warmup_steps = 0\n",
        "# The total number of training steps\n",
        "num_training_steps = epochs * len(train_loader)\n",
        "# Necessary to take into account Gradient accumulation\n",
        "num_training_steps = num_training_steps // iters_to_accumulate\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhBywFg2_42t"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_bert(\n",
        "    model, loss_func,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_loader, valid_loader,\n",
        "    epochs,\n",
        "    iters_to_accumulate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltDXezKeapLK"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0gIXu_NgehU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOjb09CVgXyZ"
      },
      "outputs": [],
      "source": [
        "def evaluate_preds(\n",
        "    model, device,\n",
        "    dataloader,\n",
        "    threshold = 0.5\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, (encoding, labels) in enumerate(tqdm(dataloader)):\n",
        "            # Converting to CUDA tensors\n",
        "            for k, v in encoding.items(): encoding[k] = v.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Get model logits and compute loss\n",
        "            logits = model(encoding)\n",
        "            # Convert logits to predictions (assuming binary classification with sigmoid)\n",
        "            preds = (torch.sigmoid(logits.squeeze(-1)) > threshold).int()\n",
        "\n",
        "            # Store predictions and labels\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return true_labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpL3n1QW0H9E"
      },
      "outputs": [],
      "source": [
        "# TODO: maybe use something other than CodeNet\n",
        "eval_data = Subset(valid_data, list(range(len(valid_data))))\n",
        "\n",
        "# Load the best weights (state that achieved the lowest validation loss)\n",
        "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "\n",
        "ls, ps = evaluate_preds(\n",
        "    model, device,\n",
        "    DataLoader(eval_data, batch_size=2, shuffle=True),\n",
        "    threshold=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLIKQEzn0K0n"
      },
      "outputs": [],
      "source": [
        "report = classification_report(ls, ps)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}