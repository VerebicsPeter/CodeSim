{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VerebicsPeter/CodeSim/blob/main/model/model_finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9rC5t03TgEv"
      },
      "source": [
        "# Code Similarity with Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHWMVk9vTgE3"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNViP9VnTgE4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pprint as pp\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "# Hugging Face Transformers (fro CodeBERT etc.)\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "# Libraries for logging\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtfdWw8jTgE7",
        "outputId": "2a60b51e-818e-406f-c5bf-3f5dbd0809c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsY6hOil070N"
      },
      "source": [
        "## Dataset Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS9pegh1dDj4"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "paired_dataset_url = f\"https://drive.google.com/uc?export=download&id={userdata.get('codenetSamplePaired')}\"\n",
        "#paired_dataset_url = \"https://drive.google.com/uc?export=download&id=1I3mbw4CIMij44vUrmf9XULZyg5lXHKwn\"  # old dataset\n",
        "#paired_dataset_url = \"https://drive.google.com/uc?export=download&id=1Mdp7FX4YBgv3i0ga69e8gxcbDvSIngDM\"  # new dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uws_FYLpwDr0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a32WbZF4CHYZ"
      },
      "outputs": [],
      "source": [
        "COLUMNS = [\n",
        "    'pid',    # CodeNet problem ID\n",
        "    'sid_1',  # CodeNet solution ID of 'src_1'\n",
        "    'sid_2',  # CodeNet solution ID of 'src_2'\n",
        "    'src_1',  # CodeNet solution code of 'sid_1'\n",
        "    'src_2',  # CodeNet solution code of 'sid_2'\n",
        "    'label',  # Label indicating if 'src_1' and 'src_2' both solve 'pid'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bis_8g7kCHYb",
        "outputId": "adcdac2b-f9bd-451e-8ad9-9e7c5bcfd794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               src_1  \\\n",
              "0  ##C - Step(TLE)\\nN = int(input())\\nA = list(ma...   \n",
              "1  S = input()\\nINF = 10 ** 9 + 7\\nlength = len(S...   \n",
              "2  import sys\\nfrom bisect import bisect_right as...   \n",
              "3  numb=input()\\ninputs = list(map(int,input().sp...   \n",
              "4  import sys, re\\nfrom math import ceil, sqrt, h...   \n",
              "\n",
              "                                               src_2  label  \n",
              "0  N=int(input())\\nA=list(map(int,input().split()...      1  \n",
              "1  s = input()\\nn = len(s)\\n\\nMOD = 10**9+7\\ndp =...      1  \n",
              "2  '''\\n研究室PCでの解答\\n'''\\nimport math\\n#import nump...      1  \n",
              "3  N = int(input())\\na = list(map(int, input().sp...      1  \n",
              "4  from itertools import permutations\\nn,m=map(in...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a56fdfa-da07-464f-b16b-5ef475865b37\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_1</th>\n",
              "      <th>src_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>##C - Step(TLE)\\nN = int(input())\\nA = list(ma...</td>\n",
              "      <td>N=int(input())\\nA=list(map(int,input().split()...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S = input()\\nINF = 10 ** 9 + 7\\nlength = len(S...</td>\n",
              "      <td>s = input()\\nn = len(s)\\n\\nMOD = 10**9+7\\ndp =...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>import sys\\nfrom bisect import bisect_right as...</td>\n",
              "      <td>'''\\n研究室PCでの解答\\n'''\\nimport math\\n#import nump...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>numb=input()\\ninputs = list(map(int,input().sp...</td>\n",
              "      <td>N = int(input())\\na = list(map(int, input().sp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>import sys, re\\nfrom math import ceil, sqrt, h...</td>\n",
              "      <td>from itertools import permutations\\nn,m=map(in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a56fdfa-da07-464f-b16b-5ef475865b37')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a56fdfa-da07-464f-b16b-5ef475865b37 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a56fdfa-da07-464f-b16b-5ef475865b37');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d19ae74-d49f-4a96-81cc-834bf2959e2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d19ae74-d49f-4a96-81cc-834bf2959e2a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d19ae74-d49f-4a96-81cc-834bf2959e2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"src_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9861,\n        \"samples\": [\n          \"from collections import defaultdict\\nimport sys\\n\\nh, w, m = map(lambda x: int(x), input().split())\\n\\ny_to_num = [0] * h\\nx_to_num = [0] * w\\nexisting_h_to_w = defaultdict(set)\\n\\n\\nfor _ in range(m):\\n    hh, ww = map(lambda x: int(x), input().split())\\n    y_to_num[hh-1] += 1\\n    x_to_num[ww-1] += 1\\n    existing_h_to_w[hh-1].add(ww-1)\\n\\nmax_vertical_num = max(y_to_num)\\nmax_horizontal_num = max(x_to_num)\\n\\ny_coor_with_max_num = [i for i, num in enumerate(y_to_num) if num == max_vertical_num]\\nx_coor_with_max_num = [i for i, num in enumerate(x_to_num) if num == max_horizontal_num]\\n\\n# print(y_coor_with_max_num, x_coor_with_max_num, existing_h_to_w)\\n\\nfor y in y_coor_with_max_num:\\n    for x in x_coor_with_max_num:\\n        if x not in existing_h_to_w[y]:\\n            print(max_vertical_num + max_horizontal_num)\\n            sys.exit()\\n\\nprint(max_vertical_num + max_horizontal_num - 1)\",\n          \"n, m = map(int, input().split())\\nh = list(map(int, input().split()))\\n\\nans = [1]* n\\nfor i in range(m):\\n    a, b = map(int, input().split())\\n    if h[a-1] >= h[b-1]:\\n        ans[b-1] = 0\\n        \\n    if h[a-1] <= h[b-1]:\\n        ans[a-1] = 0\\n        \\nprint(ans.count(1))\",\n          \"n = int(input())\\nalpha = [chr(ord('a') + i) for i in range(26)]\\ncount = 1\\nm = n\\nwhile True:\\n    m -= 26 ** count\\n    if m > 0:\\n        count += 1\\n    else:\\n        m += 26 ** count\\n        break\\nketa = count\\ndec = m - 1\\n\\ndef Base_10_to_n(X, n):\\n    if (int(X/n)):\\n        a = alpha[X%n]\\n\\n        return Base_10_to_n(int(X/n), n)+a\\n    else:\\n        a = alpha[X%n]\\n        return a\\n############################\\n \\n \\n#####\\u95a2\\u6570\\u3092\\u3064\\u304b\\u3063\\u3066\\u307f\\u308b\\uff0e#####\\n######\\u4eca\\u56de\\u306f\\u4e8c\\u9032\\u6570\\u306b\\u5909\\u63db######\\nx10 = dec\\nx2 = Base_10_to_n(x10, 26)\\nif len(x2) < count:\\n    x2 = 'a'*(count - len(x2)) + x2\\nprint( x2 )#\\\"100011\\\"\\u304c\\u8868\\u793a\\u3055\\u308c\\u308b\\uff0e\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9975,\n        \"samples\": [\n          \"def main():\\n    n=int(input())\\n    s=input()\\n    dp=[(n+1)*[0]for _ in range(n+1)]\\n    ans=0\\n    for i in range(1,n):\\n        for j in range(i+1,n+1):\\n            if s[i-1]==s[j-1]:\\n                dp[i][j]=min(dp[i-1][j-1]+1,j-i)\\n                ans=max(ans,dp[i][j])\\n    print(ans)\\nif __name__ == \\\"__main__\\\":\\n    main()\",\n          \"x, y, n = map(int, input().split())\\nbox = [[0 for _ in range(y)] for _ in range(x)]\\nfor _ in range(n):\\n    a, b = map(int, input().split())\\n    box[a - 1][b - 1] = 1\\ntable = [0] * 10\\nfor i in range(x - 2):\\n    for j in range(y - 2):\\n        total = sum(box[i][j:j + 3]) + sum(box[i + 1][j:j + 3]) + sum(box[i + 2][j:j + 3])\\n        table[total] += 1\\n\\n[print(a) for a in table]\",\n          \"import sys\\n \\ndef eat(i,j,candies,counter):\\n    s=candies[i]+candies[j]\\n    if s>x:\\n        if candies[i]>=s-x:\\n            candies[i]-=s+x\\n        else:\\n            candies[j]-=s-x-candies[i]\\n            candies[i]=0\\n        counter+=s-x\\n    return counter\\n \\ndef main(n,x,candies):\\n    counter=0\\n    for i in range(0,n-1):\\n        counter=eat(i+1,i,candies,counter)\\n    return counter\\n \\nn,x=map(int,sys.stdin.readline().strip().split())\\ncandies=list(map(int,sys.stdin.readline().strip().split()))\\nprint(main(n,x,candies))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df = pd.read_csv(paired_dataset_url, header=0, names=COLUMNS)\n",
        "df = df.drop(columns=['pid', 'sid_1', 'sid_2'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boNhtBMiTgFB"
      },
      "outputs": [],
      "source": [
        "# Code datasets (for labeled and unlabeled code snippets)\n",
        "\n",
        "class CodePairDataset(Dataset):\n",
        "    def __init__(self, codes_a, codes_b, labels, tokenizer):\n",
        "        super().__init__()\n",
        "        assert len(codes_a) == len(codes_b) == len(labels), \"Length MUST match!\"\n",
        "        self.codes_a = codes_a\n",
        "        self.codes_b = codes_b\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        code_a = self.codes_a[idx]\n",
        "        code_b = self.codes_b[idx]\n",
        "        label = self.labels[idx]\n",
        "        # Encode the sequences for sequence pair classification\n",
        "        # ([CLS], code_a tokens , [SEP], code_b tokens, [SEP])\n",
        "        encoding = self.tokenizer(\n",
        "            code_a, code_b,\n",
        "            padding='max_length',  # Pad to max_length\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "            truncation=True,       # Truncate to max_length\n",
        "            return_tensors='pt'    # Return torch.Tensor objects\n",
        "        )\n",
        "        # Remove batch dimension\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "        return encoding, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    @classmethod\n",
        "    def from_csv_data(cls, path: str, tokenizer):\n",
        "        df = pd.read_csv(path, header=0, names=COLUMNS)\n",
        "        df = df.drop(columns=['pid', 'sid_1', 'sid_2'])\n",
        "\n",
        "        # Filter out sequences that are longer then 4096 chararters\n",
        "        MAX_CHAR_COUNT = 4096\n",
        "        filter = lambda row: len(row['src_1']) + len(row['src_2']) < MAX_CHAR_COUNT\n",
        "        df = df[df.apply(filter, axis=1)]\n",
        "        print('filtered sequences:', df.shape)\n",
        "\n",
        "        srcs_x = df['src_1'].to_list()\n",
        "        srcs_y = df['src_2'].to_list()\n",
        "        labels = df['label'].to_list()\n",
        "        return cls(srcs_x, srcs_y, labels, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0yWCEhrTgE-"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I66sH2KATgE_"
      },
      "outputs": [],
      "source": [
        "# Model for finetuning\n",
        "\n",
        "class CodeSimilarityClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "        bert,  # BERT based model instance\n",
        "        freeze_bert=False,\n",
        "        dropout_rate=0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "        self.cls = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, bert_input) -> torch.Tensor:\n",
        "        with torch.device(device):\n",
        "            bert_output = self.bert(**bert_input)\n",
        "            pooler_output = bert_output.pooler_output\n",
        "            pooler_output = self.drop(pooler_output)\n",
        "            logits = self.cls(pooler_output)\n",
        "            return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCRPRlQav58Y"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enULAgCJTgFC"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(\n",
        "    model, device,\n",
        "    loss_func,\n",
        "    scaler,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    dataloader,\n",
        "    iters_to_accumulate,\n",
        "    # for logging\n",
        "    print_every=10\n",
        "):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    num_iter = len(dataloader)\n",
        "    for iter, (encoding, labels) in enumerate(tqdm(train_loader)):\n",
        "        # Converting to cuda tensors\n",
        "        for k, v in encoding.items(): encoding[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Obtaining the logits from the model\n",
        "        # Enables autocasting for the forward pass (model + loss)\n",
        "        with autocast('cuda'):\n",
        "            # Obtaining the logits from the model\n",
        "            logits = model(encoding)\n",
        "            # Computing loss\n",
        "            loss = loss_func(logits.squeeze(-1), labels.float())\n",
        "            # Normalize the loss because it is averaged\n",
        "            loss = loss / iters_to_accumulate\n",
        "\n",
        "        # Backpropagating the gradients\n",
        "        # Scales loss. (calls backward() on scaled loss to create scaled gradients)\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (iter + 1) % iters_to_accumulate == 0:\n",
        "            # Optimization step\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
        "            # otherwise, opti.step() is skipped.\n",
        "            scaler.step(optimizer)\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "            # Adjust the learning rate based on the number of iterations.\n",
        "            scheduler.step()\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print training loss information\n",
        "        if (iter + 1) % print_every == 0:\n",
        "            print(\n",
        "                f\"Iteration {iter+1}/{num_iter} complete. \" +\n",
        "                f\"Loss: {running_loss / print_every}\"\n",
        "            )\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "def evaluate_loss(\n",
        "    model, device,\n",
        "    loss_func,\n",
        "    dataloader\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    loss, count = 0,0\n",
        "    with torch.no_grad():\n",
        "        for it, (encoding, labels) in enumerate(tqdm(dataloader)):\n",
        "            # Converting to cuda tensors\n",
        "            for k, v in encoding.items(): encoding[k] = v.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(encoding)\n",
        "            loss += loss_func(logits.squeeze(-1), labels.float()).item()\n",
        "            count += 1\n",
        "\n",
        "    mean_loss = loss / count\n",
        "    return mean_loss\n",
        "\n",
        "\n",
        "def train_bert(\n",
        "    model,\n",
        "    loss_func,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_loader, valid_loader,\n",
        "    epochs,\n",
        "    iters_to_accumulate\n",
        "):\n",
        "    best_loss = np.Inf\n",
        "    iters = []\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Compute training loss\n",
        "        train_loss = train_one_epoch(\n",
        "            model, device, loss_func,\n",
        "            scaler,  # grad scaler\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            train_loader,\n",
        "            iters_to_accumulate,\n",
        "            # print the training loss 5 times per epoch\n",
        "            print_every=len(train_loader) // 5\n",
        "        )\n",
        "        # Compute validation loss\n",
        "        valid_loss = evaluate_loss(\n",
        "            model, device, loss_func,\n",
        "            valid_loader\n",
        "        )\n",
        "        print(f\"Epoch {epoch+1} complete! Validation Loss: {valid_loss}\")\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            print(f\"Best validation loss improved from {best_loss} to {valid_loss}\")\n",
        "            best_loss = valid_loss\n",
        "            # TODO: save the model\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfGO1Ktjeq7T"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "\n",
        "bert_name = \"neulab/codebert-python\"\n",
        "\n",
        "\"\"\"\n",
        "other checkpoints:\n",
        "- \"microsoft/codebert-base\"\n",
        "- \"huggingface/CodeBERTa-small-v1\"\n",
        "\"\"\"\n",
        "\n",
        "epochs = 4\n",
        "lr = 1e-5  # learning rate\n",
        "wd = 1e-5  # weight decay\n",
        "bs = 20    # batch size\n",
        "# The gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate.\n",
        "# If set to \"1\", you get the usual batch size\n",
        "iters_to_accumulate = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w5HC1kY9aMdx"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
        "\n",
        "dataset = CodePairDataset.from_csv_data(paired_dataset_url, bert_tokenizer)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "SHUFFLE = True\n",
        "train_loader = DataLoader(train_data, batch_size=bs, shuffle=SHUFFLE)\n",
        "valid_loader = DataLoader(valid_data, batch_size=bs, shuffle=SHUFFLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RmsA8R0JTgFD"
      },
      "outputs": [],
      "source": [
        "# Model instance\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(bert_name).to(device)\n",
        "\n",
        "model = CodeSimilarityClassifier(bert_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FEJc8HelobGZ"
      },
      "outputs": [],
      "source": [
        "# Optimizer and Scheduler\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "# The number of steps for the warmup phase.\n",
        "num_warmup_steps = 0\n",
        "# The total number of training steps\n",
        "num_training_steps = epochs * len(train_loader)\n",
        "# Necessary to take into account Gradient accumulation\n",
        "num_training_steps = num_training_steps // iters_to_accumulate\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhBywFg2_42t"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_bert(\n",
        "    model, loss_func,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_loader, valid_loader,\n",
        "    epochs,\n",
        "    iters_to_accumulate\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}